{"cells":[{"cell_type":"markdown","metadata":{"id":"vQ9vc_NWigTE"},"source":["# CE-40959: Advanced Machine Learning\n","## HW5 - Continual Learning (90 points)"]},{"cell_type":"markdown","metadata":{"id":"5r9Y8-G0iozQ"},"source":["In this notebook, you are going to see the `catastrophic forgetting` phenomenon in continual learning scenarios and then alleviate this problem by implementing [Gradient Episodic Memory(GEM)](https://arxiv.org/abs/1706.08840) on the `MNIST` dataset.\n","\n","\n","Please write your code in specified sections and do not change anything else. If you have a question regarding this homework, please ask it on the Quera.\n","\n","Also, it is recommended to use Google Colab to do this homework. You can connect to your drive using the code below:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39525,"status":"ok","timestamp":1656037054356,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"nGnkMrr6iCeo","outputId":"e55d2b50-b2d8-496f-b1db-d6f6333b7457"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"8oNFX6Z9tVNB"},"source":["## Import Required libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19549,"status":"ok","timestamp":1656037073899,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"aqgGYYp71AGL","outputId":"45919d98-df79-46af-c88d-0cace58df670"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting quadprog\n","  Downloading quadprog-0.1.11.tar.gz (121 kB)\n","\u001b[K     |████████████████████████████████| 121 kB 5.1 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from quadprog) (1.21.6)\n","Building wheels for collected packages: quadprog\n","  Building wheel for quadprog (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for quadprog: filename=quadprog-0.1.11-cp37-cp37m-linux_x86_64.whl size=290752 sha256=803bc49036b98da72aa385611c273727be59cb748a5fc68677d16f5b52754a29\n","  Stored in directory: /root/.cache/pip/wheels/4a/4e/d7/41034ea11aeef1266df3cae546116cb6094e955c41ae3e2589\n","Successfully built quadprog\n","Installing collected packages: quadprog\n","Successfully installed quadprog-0.1.11\n"]}],"source":["!pip install quadprog"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3870,"status":"ok","timestamp":1656037077762,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"m_9dNn8miytX"},"outputs":[],"source":["import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","import random\n","import torch.nn as nn\n","import math\n","import quadprog\n","from tqdm import tqdm\n","import pickle\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.utils.data as data"]},{"cell_type":"markdown","metadata":{"id":"9Ti3G7U5taUu"},"source":["## Learning parameters"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1656037077763,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"17H45PaUstUI"},"outputs":[],"source":["num_classes = 10\n","class_per_task = 2\n","number_of_data_per_class = 3000\n","num_tasks = int(num_classes // class_per_task)\n","batch_size = 10\n","memory_size_per_task = 10"]},{"cell_type":"markdown","metadata":{"id":"R0sdW7F8tcl1"},"source":["## Prepare dataset (5 points)"]},{"cell_type":"markdown","metadata":{"id":"C-VMIe8CzWmI"},"source":["To compare different benchmarks fairly, define all of your dataloaders for each task and save them in an array."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1656037077763,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"cQH1QR0-k_Bg"},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1656037077764,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"b-yOG-uxoaZ4"},"outputs":[],"source":["def get_all_dataloaders(num_classes, class_per_task, number_of_data_per_class, num_tasks):\n","    #################################################################################\n","    #                  COMPLETE THE FOLLOWING SECTION (2.5 points)                   #\n","    #################################################################################\n","    # complete the function to get all dataloaders for all tasks\n","    train_loader = {}\n","\n","    classes= np.arange(num_classes)\n","    np.random.shuffle(classes)\n","    \n","    for i in range(num_tasks):\n","        dataset = torchvision.datasets.MNIST('./dataset/', train=True, download=True, transform = transforms.ToTensor())\n","        idx=[dataset.targets == a for a in classes[class_per_task*i:class_per_task*(i+1)]]\n","        indexes = dataset.targets == 1000000 #want all to be False\n","\n","        for k in range(len(idx)):\n","          indexes = torch.logical_or(idx[k],indexes)\n","\n","        dataset.targets = dataset.targets[indexes][:class_per_task*number_of_data_per_class]\n","        dataset.data = dataset.data[indexes][:class_per_task*number_of_data_per_class]\n","\n","        train_loader[i] = torch.utils.data.DataLoader(\n","                dataset,\n","                batch_size=batch_size)\n","        \n","    return train_loader,classes\n","\n","    #################################################################################\n","\n","\n","def get_testloader(classes,num_task,class_per_task,number_of_data_per_class):\n","    #################################################################################\n","    #                  COMPLETE THE FOLLOWING SECTION (2.5 points)                   #\n","    #################################################################################\n","    # complete the function to get MNIST test dataloader\n","\n","    test_loader = {}\n","\n","    for i in range(num_tasks):\n","        dataset = torchvision.datasets.MNIST('./dataset/', train=False, download=True, transform = transforms.ToTensor())\n","        idx=[dataset.targets == a for a in classes[class_per_task*i:class_per_task*(i+1)]]\n","        indexes = dataset.targets == 1000000\n","\n","        for k in range(len(idx)):\n","          indexes = torch.logical_or(idx[k],indexes)\n","\n","        dataset.targets = dataset.targets[indexes]\n","        dataset.data = dataset.data[indexes]\n","\n","        test_loader[i] = torch.utils.data.DataLoader(\n","                dataset,\n","                batch_size=batch_size)\n","        \n","    return test_loader\n","    #################################################################################"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":431,"referenced_widgets":["aca3eb591e0940008d493d605832e053","7edd9311655c421193c3fe8b59e0144c","337d4110bd0248da9ca150be4970826b","9eabc50b1ef54d8aae6af8d0d345dab5","9f2e92bd49ff40d48942faa812f65233","efb0f197a1cf4717b6e27c6c3c96f3ea","280f41d39de246158d2a05fb0f0ed57b","03f47d4009c0439eb3a23e97812155a9","a1fb5183d26547a1a0ea14157f67c016","74299009d06e4cce9043f95755ccbeeb","20d9bc874e9b4b10be07d8e0ce5348e8","205ef8f993194151a5d915f65d204e69","59b8f7b32eff4cadad4cc90790927ecb","fd8f98b2f7814c06afeb571e82e6c2f0","8e1cfd30de4e4875ad7e0ba7d27cbe43","c87b8974863c43b48ff8733052eed92d","3c6724549c504f8a8ca10a8f9eb884a7","813ac878ef914ad780dea027126f4518","1dc41e4491cc431da5efa078a2799053","dcd76962d72c409b9e2b5709e39cecf9","0072319a6c3348ce9a281f44eca71cd8","7cfad5ef061a42938ca8b77958a6be0b","c2859020f2164e42b45cbaa599924a4d","b64dd9da7e73484c8348e134e826d0cf","c89d86c7003c4a358b52c26fd52614a3","72e09f1289c9459982ec4a6a54bb5f30","7b8a01a7e3b0464e80e352851800ed56","25ea3873f89441248d026e9af0042a73","339dc5ae66fe4454893ab391494ade1d","e6487a2cd5d545c0b0d06629e3907fd5","c169f4aa1c82443c9d51ef4c0bae49a7","794b93ce1eaf45eb988158fea764645e","c5c50810983544949abb13ecc144dcb4","c70d384021034870b4b3be8bde517678","4e797defe67140749a749304865dd302","60788c22e7f542b99e85f9c75163a3e5","138e4a08c0f54dc988c00769e8af28f9","ac72a241bc5642dc96b4ec906c29327b","220e2435a2874423b8f8769ae74bfbb7","31ccaea14912462d93c8cedf259b8d82","50270bb6e36d465f8298742bea231525","a7d36a048c8f44d4905759a62c4752a6","9b5136c0f30c446eab6130de377f5884","3740de8f280b4dc38abee790762be700"]},"executionInfo":{"elapsed":2396,"status":"ok","timestamp":1656037080152,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"t2y6OEPhriFt","outputId":"7e307b40-c74d-4ff8-9fb1-e5edbd266b3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aca3eb591e0940008d493d605832e053","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"205ef8f993194151a5d915f65d204e69","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2859020f2164e42b45cbaa599924a4d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c70d384021034870b4b3be8bde517678","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n","\n"]}],"source":["train_loader,classes = get_all_dataloaders(num_classes,class_per_task,number_of_data_per_class,num_tasks)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1656037080153,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"Qx6exAiOr3yR"},"outputs":[],"source":["test_loader = get_testloader(classes,num_tasks,class_per_task,number_of_data_per_class)"]},{"cell_type":"markdown","metadata":{"id":"-1TiyGp71Lyv"},"source":["## Network (5 points)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656037080153,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"n7CJ3Nrz1Y5t"},"outputs":[],"source":["# define a 3 layer fc with relu activation functions between layers\n","# your fc layers dimensions are as follows:\n","# 784, 150, 150, 10\n","\n","\n","#################################################################################\n","#                  COMPLETE THE FOLLOWING SECTION (5 points)                   #\n","#################################################################################\n","# define above mentioned model and needed variables\n","\n","class FC(torch.nn.Module):\n","    def __init__(self):\n","        super(FC, self).__init__()   \n","        self.fc1 = torch.nn.Linear(784, 150)\n","        self.fc2 = torch.nn.Linear(150, 150)\n","        self.fc3 = torch.nn.Linear(150, 10)\n","\n","    def forward(self,inp):\n","        x = torch.flatten(inp,1,-1)\n","        x = self.fc1(x)\n","        x = nn.functional.relu(x)\n","        x = self.fc2(x)\n","        x = nn.functional.relu(x)\n","        out = self.fc3(x)\n","        return out\n","\n","#################################################################################"]},{"cell_type":"markdown","metadata":{"id":"Bvv-TsoHtmN-"},"source":["## Naive Learning (20 points)"]},{"cell_type":"markdown","metadata":{"id":"NdZlDuvLtnu-"},"source":["In this section, you will learn a network in its natural state, without considering any strategy for learning it continually. You will see that learning data in a such fashion causes a phenomenon called catastrophic forgetting.\n","\n","As `GEM` is a task-incremental method, like the paper, evaluate your trained model performance for each task and then report the average accuracy of tasks. In addition to Accuracy metric, report the `backward transfer` and `forward transfer` metric based on the defination in the paper."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1656037080153,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"DNdaULuQiT1q"},"outputs":[],"source":["def train(model, trainloader, optimizer, criterion,task_id):\n","    model.train()\n","    print('Training on task',task_id)\n","    train_running_loss = 0.0\n","    train_running_correct = 0\n","    counter = 0\n","    for i, data in tqdm(enumerate(trainloader[task_id]), total=len(trainloader[task_id])):\n","        counter += 1\n","        image, labels = data\n","        image = image.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(image)\n","        loss = criterion(outputs, labels)\n","        train_running_loss += loss.item()\n","        _, preds = torch.max(outputs.data, 1)\n","        train_running_correct += (preds == labels).sum().item()\n","        loss.backward()\n","        optimizer.step()\n","    \n","    epoch_loss = train_running_loss / counter\n","    epoch_acc = 100. * (train_running_correct / len(trainloader[task_id].dataset))\n","    return epoch_loss, epoch_acc\n","\n","def validate(model, testloaders, criterion,task_id,R):\n","    model.eval()\n","    print('Validation')\n","\n","    for t,(k,testloader) in enumerate(testloaders.items()):\n","        valid_running_loss = 0.0\n","        valid_running_correct = 0\n","        counter = 0\n","        if t<=task_id:\n","          with torch.no_grad():\n","              for i, data in enumerate(testloader):\n","                  counter += 1\n","                  image, labels = data\n","                  image = image.to(device)\n","                  labels = labels.to(device)\n","                  outputs = model(image)\n","                  loss = criterion(outputs, labels)\n","                  valid_running_loss += loss.item()\n","                  _, preds = torch.max(outputs.data, 1)\n","                  valid_running_correct += (preds == labels).sum().item()\n","              if task_id == t:\n","                  epoch_loss = valid_running_loss / counter\n","              R[task_id][t] = 100. * (valid_running_correct / len(testloader.dataset))\n","    return epoch_loss, R\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1656037080154,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"LAxCHEYGiiDK"},"outputs":[],"source":["def save_model(epoch, model, optimizer, criterion,checkpoint_path,stage):\n","    \"\"\"\n","    Function to save the trained model \n","    \"\"\"\n","    print(f\"Saving model...\")\n","    torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': criterion,\n","                }, checkpoint_path+'model_stage'+str(stage)+'.pth')\n","    \n","def compute_metrics(R,task_id,baseline):\n","    diag = R.diagonal()\n","    acc = np.mean(R[task_id])\n","    BWT=0\n","    FWT=0\n","    if task_id != num_tasks-1:\n","        BWT = np.mean(R[task_id-1]-diag[task_id-1])\n","    if task_id != 0:\n","        FWT = np.mean([R[i-1][i] for i in range(task_id-1)])\n","    return acc,BWT,FWT\n","\n","def base_line(model,testloaders):\n","    baseline=[]\n","    valid_running_loss = 0.0\n","    valid_running_correct = 0\n","    for t,(k,testloader) in enumerate(testloaders.items()):\n","          model.eval()\n","          with torch.no_grad():\n","              for i, data in enumerate(testloader):\n","                  image, labels = data\n","                  image = image.to(device)\n","                  labels = labels.to(device)\n","                  outputs = model(image)\n","                  loss = criterion(outputs, labels)\n","                  valid_running_loss += loss.item()\n","                  _, preds = torch.max(outputs.data, 1)\n","                  valid_running_correct += (preds == labels).sum().item()\n","              baseline.append(100. * (valid_running_correct / len(testloader.dataset)))\n","\n","    return baseline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20069,"status":"ok","timestamp":1655990940365,"user":{"displayName":"My Workspace","userId":"04716841740021349672"},"user_tz":-270},"id":"HKL6_gTr2xAp","outputId":"9a690575-6d48-4e83-80fb-72d1d6444f17"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO]: Epoch 1 of 1 --- Task 0\n","Training on task 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 600/600 [00:01<00:00, 316.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation\n","[[93.64583333  0.          0.          0.          0.        ]\n"," [ 0.         98.66939611  0.          0.          0.        ]\n"," [ 0.          0.         98.69477912  0.          0.        ]\n"," [ 0.          0.          0.         98.98322318  0.        ]\n"," [ 0.          0.          0.          0.         98.01568989]]\n","Training loss: 2.026, training acc: 58.167\n","Acc: 18.729, BWT: -78.413, FWT:  0.000\n","--------------------------------------------------\n","TRAINING COMPLETE\n","[INFO]: Epoch 1 of 1 --- Task 1\n","Training on task 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 600/600 [00:01<00:00, 368.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"]},{"name":"stdout","output_type":"stream","text":["[[93.64583333  0.          0.          0.          0.        ]\n"," [ 0.         96.67349028  0.          0.          0.        ]\n"," [ 0.          0.         98.69477912  0.          0.        ]\n"," [ 0.          0.          0.         98.98322318  0.        ]\n"," [ 0.          0.          0.          0.         98.01568989]]\n","Training loss: 1.578, training acc: 52.733\n","Acc: 19.335, BWT: -74.917, FWT:  nan\n","--------------------------------------------------\n","TRAINING COMPLETE\n","[INFO]: Epoch 1 of 1 --- Task 2\n","Training on task 2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 600/600 [00:01<00:00, 376.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation\n","[[93.64583333  0.          0.          0.          0.        ]\n"," [ 0.         96.67349028  0.          0.          0.        ]\n"," [ 0.          0.         93.47389558  0.          0.        ]\n"," [ 0.          0.          0.         98.98322318  0.        ]\n"," [ 0.          0.          0.          0.         98.01568989]]\n","Training loss: 1.614, training acc: 37.783\n","Acc: 18.695, BWT: -77.339, FWT:  0.000\n","--------------------------------------------------\n","TRAINING COMPLETE\n","[INFO]: Epoch 1 of 1 --- Task 3\n","Training on task 3\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 600/600 [00:01<00:00, 398.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation\n","[[93.64583333  0.          0.          0.          0.        ]\n"," [ 0.         96.67349028  0.          0.          0.        ]\n"," [ 0.          0.         93.47389558  0.          0.        ]\n"," [ 0.          0.          0.         98.11896289  0.        ]\n"," [ 0.          0.          0.          0.         98.01568989]]\n","Training loss: 1.771, training acc: 55.117\n","Acc: 19.624, BWT: -74.779, FWT:  0.000\n","--------------------------------------------------\n","TRAINING COMPLETE\n","[INFO]: Epoch 1 of 1 --- Task 4\n","Training on task 4\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 600/600 [00:01<00:00, 390.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation\n","[[93.64583333  0.          0.          0.          0.        ]\n"," [ 0.         96.67349028  0.          0.          0.        ]\n"," [ 0.          0.         93.47389558  0.          0.        ]\n"," [ 0.          0.          0.         98.11896289  0.        ]\n"," [ 0.          0.          0.          0.         84.26395939]]\n","Training loss: 1.894, training acc: 30.767\n","Acc: 16.853, BWT: 0.000, FWT:  0.000\n","--------------------------------------------------\n","TRAINING COMPLETE\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = FC()\n","criterion = torch.nn.CrossEntropyLoss()\n","lr = 1e-3\n","optimizer  = torch.optim.SGD(model.parameters(), lr=lr)\n","epochs = 1\n","checkpoint_path = \"/content/drive/MyDrive/MSC1400_1/AML/HW6/Practical/Q6/checkpoints\"\n","\n","#################################################################################\n","#                  COMPLETE THE FOLLOWING SECTION (20 points)                   #\n","#################################################################################\n","# complete code for sequentially training and then\n","# evaluate your model with test data\n","R = np.empty((num_tasks,num_tasks))\n","\n","for i in range(num_tasks):\n","\n","    train_loss, valid_loss = np.empty((5,3),dtype=np.float64),np.empty((5,3),dtype=np.float64)\n","    train_acc = np.empty((5,3),dtype=np.float64)\n","\n","    for epoch in range(epochs):\n","        print(f\"[INFO]: Epoch {epoch+1} of {epochs} --- Task {i}\")\n","\n","        train_epoch_loss, train_epoch_acc = train(model, train_loader, \n","                                                optimizer, criterion,i)\n","        valid_epoch_loss, R = validate(model, test_loader,  \n","                                                    criterion,i,R)\n","        train_loss[i][0] = train_epoch_loss\n","        valid_loss[i][1] = valid_epoch_loss\n","        train_acc[i][2] = train_epoch_acc\n","        baseline = base_line(model,test_loader)\n","        print(R)\n","        acc,bwt,fwt = compute_metrics(R,i,baseline)\n","        print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n","\n","        print(f\"Acc: {acc:.3f}, BWT: {bwt:.3f}, FWT: {fwt: .3f}\")\n","\n","\n","        if epoch == 2:\n","\n","            save_model(epoch, model, optimizer, criterion,checkpoint_path,i)\n","            with open('{}train_losses.pickle'.format(checkpoint_path),'wb') as f:\n","                    pickle.dump(train_loss, f)\n","            with open('{}valid_losses.pickle'.format(checkpoint_path),'wb') as f:\n","                    pickle.dump(valid_loss, f)\n","            with open('{}train_accuracies.pickle'.format(checkpoint_path),'wb') as f:\n","                    pickle.dump(train_acc, f)\n","            with open('{}R.pickle'.format(checkpoint_path),'wb') as f:\n","                    pickle.dump(R, f)\n","\n","        print('-'*50)\n","    print('TRAINING COMPLETE')\n","\n","#################################################################################"]},{"cell_type":"markdown","metadata":{"id":"5YA2C_o3yjtx"},"source":["## Continually Learning using GEM (50 points)"]},{"cell_type":"markdown","metadata":{"id":"rkC4g3etjb_9"},"source":["In this section, you will complete the codes for the GEM method using the beforementioned parameters. Read the procedure explained in the paper. We pre-defined some functions for you. Complete them and use them in training."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1656037081682,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"0KUEnCBkpRnE"},"outputs":[],"source":["# define your main class for continually learning with GEM\n","# define all needed variables and functions, all inside this class\n","\n","class GEM(torch.nn.Module):\n","    def __init__(self,  n_inputs,n_outputs,n_tasks):\n","        super(GEM, self).__init__()   \n","        #################################################################################\n","        #                  COMPLETE THE FOLLOWING SECTION (5 points)                   #\n","        #################################################################################\n","        # define above mentioned model and needed variables\n","        self.margin = 0\n","        self.net = FC()\n","\n","        self.ce = nn.CrossEntropyLoss()\n","        self.n_outputs = n_outputs\n","\n","        self.opt = optim.SGD(self.parameters(), 1e-3)\n","\n","        self.n_memories = 5\n","        self.gpu = 'yes'\n","\n","        # allocate episodic memory\n","        self.memory_data = torch.FloatTensor(\n","            n_tasks, self.n_memories, n_inputs)\n","        self.memory_labs = torch.LongTensor(n_tasks, self.n_memories)\n","        \n","        self.memory_data = self.memory_data.cuda()\n","        self.memory_labs = self.memory_labs.cuda()\n","\n","        # allocate temporary synaptic memory\n","        self.grad_dims = []\n","        for param in self.parameters():\n","            self.grad_dims.append(param.data.numel())\n","        self.grads = torch.Tensor(sum(self.grad_dims), n_tasks)\n","        self.grads = self.grads.cuda()\n","\n","        # allocate counters\n","        self.observed_tasks = []\n","        self.old_task = -1\n","        self.mem_cnt = 0\n","        self.nc_per_task = n_outputs\n","        #################################################################################\n","\n","\n","    def calculate_past_classes_gradients(self,x,t,y):\n","        #################################################################################\n","        #                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n","        #################################################################################\n","         if len(self.observed_tasks) > 1:\n","            for tt in range(len(self.observed_tasks) - 1):\n","                self.zero_grad()\n","                # fwd/bwd on the examples in the memory\n","                past_task = self.observed_tasks[tt]\n","                offset1, offset2 = 0,self.nc_per_task\n","                ptloss = self.ce(\n","                    self.forward(\n","                        self.memory_data[past_task],\n","                        past_task)[:, offset1: offset2],\n","                    self.memory_labs[past_task] - offset1)\n","                ptloss.backward()\n","                self.grads[:, past_task].fill_(0.0)\n","                cnt = 0\n","                for param in self.parameters():\n","                  if param.grad is not None:\n","                      beg = 0 if cnt == 0 else sum(self.grad_dims[:cnt])\n","                      en = sum(self.grad_dims[:cnt + 1])\n","                      self.grads[beg: en, past_task].copy_(param.grad.data.view(-1))\n","                  cnt += 1\n","\n","\n","        #################################################################################\n","\n","    def calculate_current_task_gradients(self,x,t,y):\n","        #################################################################################\n","        #                  COMPLETE THE FOLLOWING SECTION (5 points)                    #\n","        #################################################################################\n","        self.zero_grad()\n","\n","        offset1, offset2 = 0, self.nc_per_task\n","        loss = self.ce(self.forward(x, t)[:, offset1: offset2], y - offset1)\n","        loss.backward()\n","\n","        #################################################################################\n","\n","    def project_past_Classes_gradients(self,x,t,y):\n","        #################################################################################\n","        #                  COMPLETE THE FOLLOWING SECTION (15 points)                   #\n","        #################################################################################\n","        \n","        if len(self.observed_tasks) > 1:\n","            # copy gradient\n","            store_grad(self.parameters, self.grads, self.grad_dims, t)\n","            indx = torch.cuda.LongTensor(self.observed_tasks[:-1]) if self.gpu \\\n","                else torch.LongTensor(self.observed_tasks[:-1])\n","            dotp = torch.mm(self.grads[:, t].unsqueeze(0),\n","                            self.grads.index_select(1, indx))\n","            if (dotp < 0).sum() != 0:\n","                project2cone2(self.grads[:, t].unsqueeze(1),\n","                              self.grads.index_select(1, indx), self.margin)\n","                # copy gradients back\n","                overwrite_grad(self.parameters, self.grads[:, t],\n","                               self.grad_dims)\n","        self.opt.step()\n","        #################################################################################\n","\n","\n","    def update_memory(self,x,t,y):\n","        #################################################################################\n","        #                  COMPLETE THE FOLLOWING SECTION (5 points)                    #\n","        #################################################################################\n","        if t != self.old_task:\n","            self.observed_tasks.append(t)\n","            self.old_task = t\n","\n","        # Update ring buffer storing examples from current task\n","        bsz = y.data.size(0)\n","        endcnt = min(self.mem_cnt + bsz, self.n_memories)\n","        effbsz = endcnt - self.mem_cnt\n","        self.memory_data[t, self.mem_cnt: endcnt].copy_(\n","            x.data[: effbsz])\n","        if bsz == 1:\n","            self.memory_labs[t, self.mem_cnt] = y.data[0]\n","        else:\n","            self.memory_labs[t, self.mem_cnt: endcnt].copy_(\n","                y.data[: effbsz])\n","        self.mem_cnt += effbsz\n","        if self.mem_cnt == self.n_memories:\n","            self.mem_cnt = 0\n","        #################################################################################\n","\n","    def forward(self, x):\n","        output = self.net(x)\n","        return output"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":418,"status":"ok","timestamp":1656037113924,"user":{"displayName":"Reihane Zohrabi","userId":"12398101126792495496"},"user_tz":-270},"id":"OmfwY-brgKac"},"outputs":[],"source":["\n","def store_grad(pp, grads, grad_dims, tid):\n","    \"\"\"\n","        This stores parameter gradients of past tasks.\n","        pp: parameters\n","        grads: gradients\n","        grad_dims: list with number of parameters per layers\n","        tid: task id\n","    \"\"\"\n","    # store the gradients\n","    grads[:, tid].fill_(0.0)\n","    cnt = 0\n","    for param in pp():\n","        if param.grad is not None:\n","            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n","            en = sum(grad_dims[:cnt + 1])\n","            grads[beg: en, tid].copy_(param.grad.data.view(-1))\n","        cnt += 1\n","\n","\n","def overwrite_grad(pp, newgrad, grad_dims):\n","    cnt = 0\n","    for param in pp():\n","        if param.grad is not None:\n","            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n","            en = sum(grad_dims[:cnt + 1])\n","            this_grad = newgrad[beg: en].contiguous().view(\n","                param.grad.data.size())\n","            param.grad.data.copy_(this_grad)\n","        cnt += 1\n","\n","\n","def project2cone2(gradient, memories, margin=0.5, eps=1e-3):\n","    memories_np = memories.cpu().t().double().numpy()\n","    gradient_np = gradient.cpu().contiguous().view(-1).double().numpy()\n","    t = memories_np.shape[0]\n","    P = np.dot(memories_np, memories_np.transpose())\n","    P = 0.5 * (P + P.transpose()) + np.eye(t) * eps\n","    q = np.dot(memories_np, gradient_np) * -1\n","    G = np.eye(t)\n","    h = np.zeros(t) + margin\n","    v = quadprog.solve_qp(P, q, G, h)[0]\n","    x = np.dot(v, memories_np) + gradient_np\n","    gradient.copy_(torch.Tensor(x).view(-1, 1))\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"GEM.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0072319a6c3348ce9a281f44eca71cd8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03f47d4009c0439eb3a23e97812155a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"138e4a08c0f54dc988c00769e8af28f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b5136c0f30c446eab6130de377f5884","placeholder":"​","style":"IPY_MODEL_3740de8f280b4dc38abee790762be700","value":" 5120/? [00:00&lt;00:00, 89007.12it/s]"}},"1dc41e4491cc431da5efa078a2799053":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"205ef8f993194151a5d915f65d204e69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59b8f7b32eff4cadad4cc90790927ecb","IPY_MODEL_fd8f98b2f7814c06afeb571e82e6c2f0","IPY_MODEL_8e1cfd30de4e4875ad7e0ba7d27cbe43"],"layout":"IPY_MODEL_c87b8974863c43b48ff8733052eed92d"}},"20d9bc874e9b4b10be07d8e0ce5348e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"220e2435a2874423b8f8769ae74bfbb7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25ea3873f89441248d026e9af0042a73":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"280f41d39de246158d2a05fb0f0ed57b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31ccaea14912462d93c8cedf259b8d82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"337d4110bd0248da9ca150be4970826b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03f47d4009c0439eb3a23e97812155a9","max":9912422,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a1fb5183d26547a1a0ea14157f67c016","value":9912422}},"339dc5ae66fe4454893ab391494ade1d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3740de8f280b4dc38abee790762be700":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c6724549c504f8a8ca10a8f9eb884a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e797defe67140749a749304865dd302":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_220e2435a2874423b8f8769ae74bfbb7","placeholder":"​","style":"IPY_MODEL_31ccaea14912462d93c8cedf259b8d82","value":""}},"50270bb6e36d465f8298742bea231525":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59b8f7b32eff4cadad4cc90790927ecb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c6724549c504f8a8ca10a8f9eb884a7","placeholder":"​","style":"IPY_MODEL_813ac878ef914ad780dea027126f4518","value":""}},"60788c22e7f542b99e85f9c75163a3e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50270bb6e36d465f8298742bea231525","max":4542,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7d36a048c8f44d4905759a62c4752a6","value":4542}},"72e09f1289c9459982ec4a6a54bb5f30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_794b93ce1eaf45eb988158fea764645e","placeholder":"​","style":"IPY_MODEL_c5c50810983544949abb13ecc144dcb4","value":" 1649664/? [00:00&lt;00:00, 3441008.23it/s]"}},"74299009d06e4cce9043f95755ccbeeb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"794b93ce1eaf45eb988158fea764645e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b8a01a7e3b0464e80e352851800ed56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cfad5ef061a42938ca8b77958a6be0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7edd9311655c421193c3fe8b59e0144c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efb0f197a1cf4717b6e27c6c3c96f3ea","placeholder":"​","style":"IPY_MODEL_280f41d39de246158d2a05fb0f0ed57b","value":""}},"813ac878ef914ad780dea027126f4518":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e1cfd30de4e4875ad7e0ba7d27cbe43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0072319a6c3348ce9a281f44eca71cd8","placeholder":"​","style":"IPY_MODEL_7cfad5ef061a42938ca8b77958a6be0b","value":" 29696/? [00:00&lt;00:00, 422645.50it/s]"}},"9b5136c0f30c446eab6130de377f5884":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eabc50b1ef54d8aae6af8d0d345dab5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74299009d06e4cce9043f95755ccbeeb","placeholder":"​","style":"IPY_MODEL_20d9bc874e9b4b10be07d8e0ce5348e8","value":" 9913344/? [00:00&lt;00:00, 15933341.23it/s]"}},"9f2e92bd49ff40d48942faa812f65233":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1fb5183d26547a1a0ea14157f67c016":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7d36a048c8f44d4905759a62c4752a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac72a241bc5642dc96b4ec906c29327b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aca3eb591e0940008d493d605832e053":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7edd9311655c421193c3fe8b59e0144c","IPY_MODEL_337d4110bd0248da9ca150be4970826b","IPY_MODEL_9eabc50b1ef54d8aae6af8d0d345dab5"],"layout":"IPY_MODEL_9f2e92bd49ff40d48942faa812f65233"}},"b64dd9da7e73484c8348e134e826d0cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25ea3873f89441248d026e9af0042a73","placeholder":"​","style":"IPY_MODEL_339dc5ae66fe4454893ab391494ade1d","value":""}},"c169f4aa1c82443c9d51ef4c0bae49a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2859020f2164e42b45cbaa599924a4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b64dd9da7e73484c8348e134e826d0cf","IPY_MODEL_c89d86c7003c4a358b52c26fd52614a3","IPY_MODEL_72e09f1289c9459982ec4a6a54bb5f30"],"layout":"IPY_MODEL_7b8a01a7e3b0464e80e352851800ed56"}},"c5c50810983544949abb13ecc144dcb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c70d384021034870b4b3be8bde517678":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e797defe67140749a749304865dd302","IPY_MODEL_60788c22e7f542b99e85f9c75163a3e5","IPY_MODEL_138e4a08c0f54dc988c00769e8af28f9"],"layout":"IPY_MODEL_ac72a241bc5642dc96b4ec906c29327b"}},"c87b8974863c43b48ff8733052eed92d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c89d86c7003c4a358b52c26fd52614a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6487a2cd5d545c0b0d06629e3907fd5","max":1648877,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c169f4aa1c82443c9d51ef4c0bae49a7","value":1648877}},"dcd76962d72c409b9e2b5709e39cecf9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6487a2cd5d545c0b0d06629e3907fd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efb0f197a1cf4717b6e27c6c3c96f3ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd8f98b2f7814c06afeb571e82e6c2f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dc41e4491cc431da5efa078a2799053","max":28881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcd76962d72c409b9e2b5709e39cecf9","value":28881}}}}},"nbformat":4,"nbformat_minor":0}
