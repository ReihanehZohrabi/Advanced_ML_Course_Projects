{"cells":[{"cell_type":"markdown","metadata":{"id":"Oma2ZStyqpQe"},"source":["# CE-40959: Advanced Machine Learning\n","## HW2 - Optimization-based Meta Learning (100 points)\n"]},{"cell_type":"markdown","metadata":{"id":"zATL8bguriGR"},"source":["In this notebook, you are going to implement a optimization-based meta learner using the `Omniglot` dataset.\n","\n","Please write your code in specified sections and do not change anything else. If you have a question regarding this homework, please ask it on the Quera.\n","\n","Also, it is recommended to use Google Colab to do this homework. You can connect to your drive using the code below:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3729,"status":"ok","timestamp":1649705041545,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"pSsY1Jw7pwZc","outputId":"e3910e3f-41d2-4632-efea-2445d26c4264"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"fZJ_Hv8Uqoil"},"source":["## Import Required libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":773,"status":"ok","timestamp":1649705042314,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"2NGBSeo0L6Vu"},"outputs":[],"source":["import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","import random\n","import torch.nn as nn\n","import math\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.utils.data as data\n","from copy import deepcopy\n","import pickle\n","from tqdm.auto import tqdm"]},{"cell_type":"markdown","metadata":{"id":"xabeci_XPcU2"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"mNHVKqRMM2oD"},"source":["In Meta-Learning literature and in the meta-training phase, you are given some batches which consist of `support` and `query` sets. you train your model in a way that by using a support set you could predict query set labels correctly.\n","\n","The pioneer of this branch is Model-Agnostic Meta-Learning(MAML). \n","\n","First, we should build the dataset in this way that each batch returns N*(k+k') images. `k` is the number of support images per class and `k'` is the number of query images per class in a batch.\n","\n","The Omniglot data set is designed for developing more human-like learning algorithms. It contains 1623 different handwritten characters from 50 different alphabets. Each of the 1623 characters was drawn online via Amazon's Mechanical Turk by 20 different people.\n","\n","Train and test dataset contains 964 and 659 classes, respectively. Torchvision-based Omniglot dataset is ordered and every 20 images in a row belong to one class."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":714,"status":"ok","timestamp":1649705090609,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"ZU6nY6ZPDJla"},"outputs":[],"source":["# Meta learning parameters.\n","\n","N = 5\n","support_size = 1\n","query_size = 15\n","meta_inner_lr = 0.4\n","meta_outer_lr = 0.001"]},{"cell_type":"markdown","metadata":{"id":"Z8bS05XnPe7v"},"source":["## Prepare dataset (5 points)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":562,"status":"ok","timestamp":1649705042874,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"pMXx6_Py9AhO","outputId":"5ae7a142-b65d-45a7-fbad-0343703e25b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["transform = transforms.Compose([\n","    transforms.Resize(28),\n","    transforms.ToTensor(),\n","    transforms.Normalize(0.5, 0.5)\n","])\n","\n","train_dataset = torchvision.datasets.Omniglot('./data/omniglot/', download = True, background = True, transform = transform)\n","test_dataset = torchvision.datasets.Omniglot('./data/omniglot/', download = True, background = False, transform = transform)\n","\n","train_labels = np.repeat(np.arange(964), 20)\n","test_labels = np.repeat(np.arange(659), 20)"]},{"cell_type":"markdown","metadata":{"id":"oWK0vksv4nVh"},"source":["To build a dataloader, we should have a class that yields indexes of selected data in the dataset for every iteration and pass it to the `batch_sampler` attribute of dataloader.\n","\n","Complete below code based on this pseudocode:\n","\n","\n","1.   select `N` classes randomly from all classes\n","2.   select `support_size + query_size` images from each classes independently and randomly\n","3.   shuffle dataset indexes, but don't forget to put query indexes at the last of the list"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1649705042874,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"yODgabjHEY9A"},"outputs":[],"source":["class BatchSampler(object):\n","    '''\n","    BatchSampler: yield a batch of indexes at each iteration.\n","    __len__ returns the number of episodes per epoch (same as 'self.iterations').\n","    '''\n","\n","    def __init__(self, labels, classes_per_it, num_samples_support, num_samples_query, iterations, batch_size):\n","        '''\n","        Initialize the BatchSampler object\n","        Args:\n","        - labels: array of labels of dataset.\n","        - classes_per_it: number of random classes for each iteration\n","        - num_samples: number of samples for each iteration for each class\n","        - iterations: number of iterations (episodes) per epoch\n","        - batch_size: number of batches per iteration\n","        '''\n","        super(BatchSampler, self).__init__()\n","        self.labels = labels\n","        self.classes_per_it = classes_per_it\n","        self.supports_per_class = num_samples_support\n","        self.queries_per_class = num_samples_query\n","        self.iterations = iterations\n","        self.batch_size = batch_size\n","        self.classes = np.unique(self.labels)\n","\n","    def __iter__(self):\n","        '''\n","        yield a batch of indexes\n","        '''\n","        S = self.supports_per_class\n","        Q = self.queries_per_class\n","\n","        for it in range(self.iterations):\n","            total_batch_indexes = np.array([])\n","            #################################################################################\n","            #                  COMPLETE THE FOLLOWING SECTION (5 points)                    #\n","            #################################################################################\n","            # feel free to add/edit initialization part of sampler.\n","            #################################################################################\n","            for b in range(self.batch_size):\n","              batch = np.array([])\n","              random_classes = np.random.choice(self.classes, self.classes_per_it, False)\n","              num_samples = S + Q\n","              support_indexes = np.zeros(self.classes_per_it * S)\n","              query_indexes = np.zeros(self.classes_per_it * Q)\n","\n","              for i, c in enumerate(random_classes):\n","                  random_indices = np.random.randint(20*c, 20*c+20, size=num_samples)\n","                  support_indexes[i * S : (i+1) * S] = random_indices[:S]\n","                  query_indexes[i * Q : (i+1) * Q] = random_indices[S:]\n","\n","              np.random.shuffle(support_indexes) \n","              np.random.shuffle(query_indexes) \n","              support_indexes = support_indexes.astype(int)\n","              query_indexes = query_indexes.astype(int)\n","              batch = np.concatenate((support_indexes, query_indexes))\n","              total_batch_indexes = np.concatenate((total_batch_indexes, batch))\n","   \n","            #################################################################################\n","            #                                   THE END                                     #\n","            #################################################################################\n","\n","            yield total_batch_indexes.astype(int)\n","    def __len__(self):\n","        return self.iterations"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":789,"status":"ok","timestamp":1649705094841,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"vkaRutIUPF4b"},"outputs":[],"source":["iterations = 5000\n","batch_size = 32\n","\n","train_sampler = BatchSampler(labels=train_labels, classes_per_it=N,\n","                              num_samples_support= support_size ,num_samples_query= query_size, iterations=iterations,\n","                              batch_size=batch_size)\n","\n","test_sampler = BatchSampler(labels=test_labels, classes_per_it=N,\n","                              num_samples_support= support_size ,num_samples_query= query_size, iterations=iterations,\n","                              batch_size=batch_size)\n","\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_sampler)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_sampler)"]},{"cell_type":"markdown","metadata":{"id":"xnvAPmPmPh92"},"source":["## Model (45 points)"]},{"cell_type":"markdown","metadata":{"id":"52JCi9o-M2sp"},"source":["Let's Build our model. the whole model is `ProtoNet` feature extractor which is used in [Prototypical Network paper](https://arxiv.org/abs/1703.05175) but due to the lack of enough computational resources for first part of question, we give you some part of the network as pretraining and only you will do meta-training on the last layer of the network."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1649705044937,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"eY3brHqVVXdb"},"outputs":[],"source":["def conv_block(in_channels, out_channels):\n","    return nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","            nn.BatchNorm2d(out_channels, momentum=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","\n","class Feature_extractor(nn.Module):\n","    '''\n","    source: https://github.com/jakesnell/prototypical-networks/blob/f0c48808e496989d01db59f86d4449d7aee9ab0c/protonets/models/few_shot.py#L62-L84\n","    '''\n","    def __init__(self, x_dim=1, hid_dim=64):\n","        super(Feature_extractor, self).__init__()\n","        self.encoder = nn.Sequential(\n","            conv_block(x_dim, hid_dim),\n","            conv_block(hid_dim, hid_dim),\n","            conv_block(hid_dim, hid_dim)\n","        )\n","\n","    def forward(self, x):\n","        return self.encoder(x)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4482,"status":"ok","timestamp":1649705051520,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"QEucQ0e669mc","outputId":"9fd97628-ce4e-43c4-a765-53cd078b07be"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","feature_extractor = Feature_extractor()\n","feature_extractor = feature_extractor.to(device)\n","feature_extractor.load_state_dict(torch.load('/content/drive/MyDrive/MSC1400_1/AML/HW2/Practical/pretrained_model.pt', map_location=device))"]},{"cell_type":"markdown","metadata":{"id":"uVFRmUfM7UN2"},"source":["To be specific, you are going to get the features of each image via the feature extraction network and give the output of that as input to your meta-learner. at the end of initialization, you should have initialized your network parameters and have saved them on the given ParameterList for future forward passes.\n","\n","The `Learner` class is a module that initializes your meta-parameters based on your given config as input. the format of config is arbitrary and you should prepare required parameters for initializing your submodules. do a quick look at the modules of meta-network to implement your Learner class.\n","\n","At forwarding pass, you give your input and two optional attributes.\n","\n","1.   **vars**: the default value of this attribute is None and it means that meta-learner will use its own parameters for forwarding pass, but you can give your desired parameters for computing output\n","2.   **bn_training**: if True, batch normalization layers show the same behavior as training time.\n","\n","\n","In the `zero_grad` method, you are going to set the gradient of given parameters as attribute or class parameters (self.vars) to zero.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":800,"status":"ok","timestamp":1649705052316,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"S7QX9qUnBLSm"},"outputs":[],"source":["class Learner(nn.Module):\n","\n","    def __init__(self, *args, **kwargs):\n","        super(Learner, self).__init__()\n","\n","        # this dict contains all tensors needed to be optimized\n","        self.vars = nn.ParameterList()\n","        # running_mean and running_var\n","        self.vars_bn = nn.ParameterList()\n","\n","        self.config =  kwargs['config']\n","        self.f_e = kwargs['fe'] #if true this means that the meta parameters are just the last layer's parameters else the whole pretrained network+lastlayer is the metalearner\n","        self.device = kwargs['device'] \n","\n","        #################################################################################\n","        #                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n","        #################################################################################\n","        # initialize your meta-network parameters based on given config.\n","        #################################################################################\n","\n","        for i, (name, param) in enumerate(self.config):\n","\n","            if name is 'conv2d':\n","                w = nn.Parameter(torch.ones(*param[:4]))\n","                torch.nn.init.kaiming_normal_(w)\n","                self.vars.append(w)\n","                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n","\n","            elif name is 'linear':\n","                w = nn.Parameter(torch.ones(*param))\n","                torch.nn.init.kaiming_normal_(w)\n","                self.vars.append(w)\n","                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n","\n","            elif name is 'bn':\n","                w = nn.Parameter(torch.ones(param[0]))\n","                self.vars.append(w)\n","                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n","\n","                running_mean = nn.Parameter(torch.zeros(param[0]), requires_grad=False)\n","                running_var = nn.Parameter(torch.ones(param[0]), requires_grad=False)\n","                self.vars_bn.extend([running_mean, running_var])\n","                self.vars.to(device)\n","                self.vars_bn.to(device)\n","\n","            elif name in ['relu', 'max_pool2d','flatten']:\n","                continue\n","            else:\n","                raise NotImplementedError\n","\n","        #################################################################################\n","        #                                   THE END                                     #\n","        #################################################################################\n","\n","\n","    def forward(self, x, vars=None, bn_training=True,Fe=False):\n","\n","        #################################################################################\n","        #                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n","        #################################################################################\n","        # compute output of input with given parameters or class parameters\n","        #################################################################################\n","\n","        if vars is None:\n","            vars = self.vars\n","\n","        idx = 0\n","        bn_idx = 0\n","        if self.f_e:\n","          x = feature_extractor(x)\n","\n","        for name, param in self.config:\n","            if name is 'conv2d':\n","                w, b = vars[idx], vars[idx + 1]\n","                x = F.conv2d(x, w, b, stride=param[4], padding=param[5])\n","                idx += 2\n","            \n","            elif name is 'linear':\n","                w, b = vars[idx], vars[idx + 1]\n","                x = F.linear(x, w, b)\n","                idx += 2\n","\n","            elif name is 'bn':\n","                w, b = vars[idx], vars[idx + 1]\n","                running_mean, running_var = self.vars_bn[bn_idx], self.vars_bn[bn_idx+1]\n","                x = F.batch_norm(x, running_mean, running_var, weight=w, bias=b, training=bn_training)\n","                idx += 2\n","                bn_idx += 2\n","\n","            elif name is 'flatten':\n","                x = x.view(x.size(0), -1)\n","\n","            elif name is 'relu':\n","                x = F.relu(x, inplace=param[0])\n","            \n","            elif name is 'max_pool2d':\n","                x = F.max_pool2d(x, param[0], param[1], param[2])\n","           \n","            else:\n","                raise NotImplementedError\n","\n","        assert idx == len(vars)\n","        assert bn_idx == len(self.vars_bn)\n","        return x\n","\n","        #################################################################################\n","        #                                   THE END                                     #\n","        #################################################################################\n","\n","\n","    def zero_grad(self, vars=None):\n","\n","        #################################################################################\n","        #                  COMPLETE THE FOLLOWING SECTION (5 points)                    #\n","        #################################################################################\n","        # set gradient of given parameters as attribute or class parameters to zero\n","        #################################################################################\n","        with torch.no_grad():\n","            if vars is not None:\n","                for param in vars:\n","                    if param.grad is not None:\n","                        param.grad.zero_()\n","            else:\n","                for param in self.vars:\n","                    if param.grad is not None:\n","                        param.grad.zero_()\n","        #################################################################################\n","        #                                   THE END                                     #\n","        #################################################################################\n","\n","    def parameters(self):\n","        return self.vars"]},{"cell_type":"markdown","metadata":{"id":"JHnhkgpMPk-Z"},"source":["Now at the `Meta` module, you implement your meta-learner module. you give your all support and query data to your module and the model will update your `Learner` parameters based on MAML-loss.\n","to clarify, you pass your support data to `Learner` and then calculate the loss on them and update your parameters and then continue to update your parameters based on the given number of inner-loop updates and finally calculate the loss on query data and update `Learner` parameters"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":989,"status":"ok","timestamp":1649714941389,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"b9ebAUChOy68"},"outputs":[],"source":["class Meta(nn.Module):\n","    def __init__(self, *args, **kwargs):\n","\n","        super(Meta, self).__init__()\n","\n","        #################################################################################\n","        #                  COMPLETE THE FOLLOWING SECTION (5 points)                   #\n","        #################################################################################\n","        # initialize your meta-learner\n","        #################################################################################\n","        self.update_lr = kwargs['update_lr']\n","        self.meta_lr = kwargs['meta_lr']\n","        self.n_way = kwargs['n_way']\n","        self.k_spt = kwargs['k_spt']\n","        self.k_qry = kwargs['k_qry']\n","        self.update_step = kwargs['update_step']\n","        self.update_step_test = kwargs['update_step_test']\n","        self.net = Learner(config=kwargs['config'],fe=kwargs['fe'],device=kwargs['device'])\n","        self.meta_optim = optim.Adam(self.net.parameters(), lr=self.meta_lr)\n","\n","        #################################################################################\n","        #                                   THE END                                     #\n","        #################################################################################\n","\n","\n","    def forward(self, x_spt, y_spt, x_qry, y_qry):\n","\n","        #################################################################################\n","        #                  COMPLETE THE FOLLOWING SECTION (15 points)                   #\n","        #################################################################################\n","        # meta-train your parameters.\n","        #################################################################################\n","\n","        task_num, setsz, c_, h, w = x_spt.size()\n","        querysz = x_qry.size(1)\n","\n","        losses_q = [0 for _ in range(self.update_step + 1)]  # losses_q[i] is the loss on step i\n","        corrects = [0 for _ in range(self.update_step + 1)]\n","\n","\n","        for i in range(task_num):\n","            logits = self.net(x_spt[i], vars=None, bn_training=True)\n","            loss = F.cross_entropy(logits, y_spt[i])\n","            grad = torch.autograd.grad(loss, self.net.parameters())\n","            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, self.net.parameters())))\n","\n","            with torch.no_grad():\n","                logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=True)\n","                loss_q = F.cross_entropy(logits_q, y_qry[i])\n","                losses_q[0] += loss_q\n","\n","                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n","                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n","                corrects[0] = corrects[0] + correct\n","\n","            with torch.no_grad():\n","                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n","                loss_q = F.cross_entropy(logits_q, y_qry[i])\n","                losses_q[1] += loss_q\n","                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n","                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n","                corrects[1] = corrects[1] + correct\n","\n","            for k in range(1, self.update_step):\n","                logits = self.net(x_spt[i], fast_weights, bn_training=True)\n","                loss = F.cross_entropy(logits, y_spt[i])\n","                grad = torch.autograd.grad(loss, fast_weights)\n","                fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights)))\n","\n","                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n","                loss_q = F.cross_entropy(logits_q, y_qry[i])\n","                losses_q[k + 1] += loss_q\n","\n","                with torch.no_grad():\n","                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n","                    correct = torch.eq(pred_q, y_qry[i]).sum().item()  # convert to numpy\n","                    corrects[k + 1] = corrects[k + 1] + correct\n","\n","\n","        torch.save(self.net.state_dict(), '/content/drive/MyDrive/MSC1400_1/AML/HW2/Practical/model4.pt')\n","        loss_q = losses_q[-1] / task_num\n","        self.meta_optim.zero_grad()\n","        loss_q.requires_grad = True\n","        loss_q.backward()\n","        self.meta_optim.step()\n","\n","        accs = np.array(corrects) / (querysz * task_num)\n","      \n","        return accs\n","\n","\n","\n","        #################################################################################\n","        #                                   THE END                                     #\n","        #################################################################################\n","\n","\n","    def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n","      \n","        assert len(x_spt.shape) == 4\n","\n","        querysz = x_qry.shape[0]\n","\n","        corrects = [0 for _ in range(self.update_step_test + 1)]\n","\n","        # in order to not ruin the state of running_mean/variance and bn_weight/bias\n","        # we finetunning on the copied model instead of self.net\n","        net = deepcopy(self.net)\n","\n","        logits = net(x_spt)\n","        loss = F.cross_entropy(logits, y_spt)\n","        grad = torch.autograd.grad(loss, net.parameters())\n","        fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters())))\n","\n","        with torch.no_grad():\n","            logits_q = net(x_qry, net.parameters(), bn_training=True)\n","            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n","            correct = torch.eq(pred_q, y_qry).sum().item()\n","            corrects[0] = corrects[0] + correct\n","\n","        with torch.no_grad():\n","            logits_q = net(x_qry, fast_weights, bn_training=True)\n","            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n","            correct = torch.eq(pred_q, y_qry).sum().item()\n","            corrects[1] = corrects[1] + correct\n","\n","        for k in range(1, self.update_step_test):\n","            logits = net(x_spt, fast_weights, bn_training=True)\n","            loss = F.cross_entropy(logits, y_spt)\n","            grad = torch.autograd.grad(loss, fast_weights)\n","            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights)))\n","\n","            logits_q = net(x_qry, fast_weights, bn_training=True)\n","            loss_q = F.cross_entropy(logits_q, y_qry)\n","\n","            with torch.no_grad():\n","                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n","                correct = torch.eq(pred_q, y_qry).sum().item()  \n","                corrects[k + 1] = corrects[k + 1] + correct\n","        del net\n","        accs = np.array(corrects) / querysz\n","\n","        return accs\n"]},{"cell_type":"markdown","metadata":{"id":"qgbrX1ykMYre"},"source":["## With Feature Extractor"]},{"cell_type":"markdown","metadata":{"id":"QC9bnPrdDI-F"},"source":["Your Meta-network which you are going to initialize your Learner based on it for first part of question is as follows:\n","\n","\n","1.   **Conv2d layer**: in_channels=64, out_channels:64, kernel_size=3, stride=1, padding=1\n","2.   **BatchNorm2D layer**: out_channels=64\n","3.   **ReLU activation**\n","4.   **Max Pooling layer**: kernel_size = 2, stride = 2\n","5.   **Flatten layer**\n","6.   **Linear layer**: in_features=64, out_features=N (number of classes in meta-learning)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5aP7sZNrE2Jr"},"source":["Meta-train **three** different networks with three different inner loop updates=[1, 2, 3]. after some reasonable epochs, plot accuracy of meta-test phase based on inner loop update parameter on each network."]},{"cell_type":"markdown","metadata":{"id":"si_-sVXgbYbr"},"source":["### Train (25 points)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":674,"status":"ok","timestamp":1649705058051,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"8QLf6-pVzaSN"},"outputs":[],"source":["def map_labels(labels,size):\n","       for i in range (0,len(labels),size):\n","          true_labels = set(labels[i:i+size].tolist())\n","          map = {}\n","          for j, l in enumerate(true_labels):\n","            map[l] = j\n","          for j in range (size):\n","            labels[i+j] = map[labels[i+j].item()]\n","          return labels"]},{"cell_type":"markdown","metadata":{"id":"5lbh4UJKUpaF"},"source":["در این قسمت سه بار عملیات ترین برای تعداد تکرارهای ۱و۲و۳ برای حلقه داخلی انجام شده است و در هر سه بار به تعداد ۲۰۰۰ ایپاک ران شده است که در زیر خروجی های هزار ایپاک آخر هرکدام را مشاهده میکنیم (با توجه به محدودیت زمان به تعداد بیشتر ران نکردیم)"]},{"cell_type":"markdown","metadata":{"id":"pcRrJxruFYpW"},"source":["# Update Step 1"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1718788,"status":"ok","timestamp":1649704780835,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"kOYjJv9u9n3X","outputId":"efb2252b-dd8e-43c5-8cdb-c7b40f6a0f20"},"outputs":[{"name":"stdout","output_type":"stream","text":["Meta(\n","  (net): Learner(\n","    (vars): ParameterList(\n","        (0): Parameter containing: [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)]\n","        (1): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (2): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (3): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (4): Parameter containing: [torch.cuda.FloatTensor of size 5x64 (GPU 0)]\n","        (5): Parameter containing: [torch.cuda.FloatTensor of size 5 (GPU 0)]\n","    )\n","    (vars_bn): ParameterList(\n","        (0): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (1): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","    )\n","  )\n",")\n","Total trainable tensors: 37381\n","step: 1050 \ttraining acc: 0.525\n","step: 1100 \ttraining acc: 0.5791666666666667\n","step: 1150 \ttraining acc: 0.5454166666666667\n","step: 1200 \ttraining acc: 0.53\n","step: 1250 \ttraining acc: 0.5291666666666667\n","step: 1300 \ttraining acc: 0.5104166666666666\n","step: 1350 \ttraining acc: 0.5483333333333333\n","step: 1400 \ttraining acc: 0.5483333333333333\n","step: 1450 \ttraining acc: 0.5533333333333333\n","step: 1500 \ttraining acc: 0.5120833333333333\n","Test acc: 0.5396\n","step: 1550 \ttraining acc: 0.5366666666666666\n","step: 1600 \ttraining acc: 0.5420833333333334\n","step: 1650 \ttraining acc: 0.5625\n","step: 1700 \ttraining acc: 0.5295833333333333\n","step: 1750 \ttraining acc: 0.5520833333333334\n","step: 1800 \ttraining acc: 0.5404166666666667\n","step: 1850 \ttraining acc: 0.5416666666666666\n","step: 1900 \ttraining acc: 0.555\n","step: 1950 \ttraining acc: 0.5520833333333334\n","step: 2000 \ttraining acc: 0.5708333333333333\n","Test acc: 0.533\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#################################################################################\n","#                  COMPLETE THE FOLLOWING SECTION (25 points)                   #\n","#################################################################################\n","# Define your config and initialize model and parameters\n","# prepare your data as input to your model.\n","# train meta-network\n","# get acurracy of model in meta-test phase\n","#################################################################################\n","epochs = 2000\n","config = [\n","        ('conv2d', [64, 64, 3, 3, 1, 1]),\n","        ('bn', [64]),\n","        ('relu', [True]),\n","        ('max_pool2d', [2,2,0]),\n","        ('flatten', []),\n","        ('linear', [N, 64])\n","    ]\n","\n","maml = Meta(config=config,fe=True,update_lr=meta_inner_lr,meta_lr=meta_outer_lr,n_way=N,\n","            k_spt=support_size,k_qry=query_size,update_step=1,update_step_test=1,device=device).to(device)\n","\n","tmp = filter(lambda x: x.requires_grad, maml.parameters())\n","num = sum(map(lambda x: np.prod(x.shape), tmp))\n","print(maml)\n","print('Total trainable tensors:', num)\n","\n","\n","for step in range(epochs+1):\n","\n","    x,y = iter(train_dataloader).next()\n","\n","    x_spt = np.empty(shape=(batch_size,N*support_size,1,28,28))\n","    x_qry = np.empty(shape=(batch_size,N*query_size,1,28,28))\n","    y_spt = np.empty(shape=(batch_size,N*support_size))\n","    y_qry = np.empty(shape=(batch_size,N*query_size))\n","    map_y_spt = np.empty(shape=(batch_size,N*support_size))\n","    map_y_qry = np.empty(shape=(batch_size,N*query_size))\n","\n","    num = (support_size+query_size)*N\n","\n","    for i in range(batch_size):\n","      x_spt[i]=x[i*(num):i*(num)+support_size*N]\n","      x_qry[i]=x[i*(num)+support_size*N:(i+1)*(num)]\n","      y_spt[i]=y[i*(num):i*(num)+support_size*N]\n","      y_qry[i]=y[i*(num)+support_size*N:(i+1)*(num)]\n","      map_y_spt[i] = map_labels(torch.from_numpy(y_spt[i]),N*support_size)\n","      map_y_qry[i] = map_labels(torch.from_numpy(y_qry[i]),N*query_size)\n","    x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device,dtype=torch.float), torch.from_numpy(y_spt).type(torch.LongTensor).to(device), \\\n","                                        torch.from_numpy(x_qry).to(device,dtype=torch.float), torch.from_numpy(y_qry).type(torch.LongTensor).to(device)\n","    \n","\n","\n","    map_y_spt = torch.from_numpy(map_y_spt).type(torch.LongTensor).to(device)\n","    map_y_qry = torch.from_numpy(map_y_qry).type(torch.LongTensor).to(device)\n","\n","    accs = maml(x_spt, map_y_spt, x_qry, map_y_qry)\n","    with open('/content/drive/MyDrive/MSC1400_1/AML/HW2/Practical/metatrain_1_acc.pickle', 'wb') as handle:\n","        pickle.dump(accs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    if step % 50 == 0:\n","            print('step:', step, '\\ttraining acc:', accs[-1])\n","\n","    if step % 500 == 0:\n","            accs = []\n","            for _ in range(1000//batch_size):\n","              # test\n","              x,y = iter(test_dataloader).next()\n","\n","              x_spt = np.empty(shape=(batch_size,N*support_size,1,28,28))\n","              x_qry = np.empty(shape=(batch_size,N*query_size,1,28,28))\n","              y_spt = np.empty(shape=(batch_size,N*support_size))\n","              y_qry = np.empty(shape=(batch_size,N*query_size))\n","              map_y_spt = np.empty(shape=(batch_size,N*support_size))\n","              map_y_qry = np.empty(shape=(batch_size,N*query_size))\n","              num = (support_size+query_size)*N\n","\n","              for i in range(batch_size):\n","                x_spt[i]=x[i*(num):i*(num)+support_size*N]\n","                x_qry[i]=x[i*(num)+support_size*N:(i+1)*(num)]\n","                y_spt[i]=y[i*(num):i*(num)+support_size*N]\n","                y_qry[i]=y[i*(num)+support_size*N:(i+1)*(num)]\n","                map_y_spt[i] = map_labels(y_spt[i],N*support_size)\n","                map_y_qry[i] = map_labels(y_qry[i],N*query_size)\n","              x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device,dtype=torch.float), torch.from_numpy(y_spt).type(torch.LongTensor).to(device), \\\n","                                        torch.from_numpy(x_qry).to(device,dtype=torch.float), torch.from_numpy(y_qry).type(torch.LongTensor).to(device)\n","    \n","              map_y_spt = torch.from_numpy(map_y_spt).type(torch.LongTensor).to(device)\n","              map_y_qry = torch.from_numpy(map_y_qry).type(torch.LongTensor).to(device)\n","              for x_spt_one, y_spt_one, x_qry_one, y_qry_one in zip(x_spt, map_y_spt, x_qry, map_y_qry):\n","                    test_acc = maml.finetunning(x_spt_one, y_spt_one, x_qry_one, y_qry_one)\n","                    accs.append( test_acc )\n","\n","            accs = np.array(accs).mean(axis=0).astype(np.float16)\n","            with open('/content/drive/MyDrive/MSC1400_1/AML/HW2/Practical/metatest_1_acc.pickle', 'wb') as handle:\n","                pickle.dump(accs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","            print('Test acc:', accs[-1])\n","\n","#################################################################################\n","#                                   THE END                                     #\n","#################################################################################\n"]},{"cell_type":"markdown","metadata":{"id":"GeRJaDFNEd3P"},"source":["# Update Step 2"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2163760,"status":"ok","timestamp":1649709495444,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"S7jI0aS0NuWu","outputId":"ac0e078e-770e-4da3-8e41-c68c9cbfc760"},"outputs":[{"name":"stdout","output_type":"stream","text":["Meta(\n","  (net): Learner(\n","    (vars): ParameterList(\n","        (0): Parameter containing: [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)]\n","        (1): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (2): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (3): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (4): Parameter containing: [torch.cuda.FloatTensor of size 5x64 (GPU 0)]\n","        (5): Parameter containing: [torch.cuda.FloatTensor of size 5 (GPU 0)]\n","    )\n","    (vars_bn): ParameterList(\n","        (0): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (1): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","    )\n","  )\n",")\n","Total trainable tensors: 37381\n","step: 1050 \ttraining acc: 0.7933333333333333\n","step: 1100 \ttraining acc: 0.7966666666666666\n","step: 1150 \ttraining acc: 0.8254166666666667\n","step: 1200 \ttraining acc: 0.7783333333333333\n","step: 1250 \ttraining acc: 0.8145833333333333\n","step: 1300 \ttraining acc: 0.8475\n","step: 1350 \ttraining acc: 0.8745833333333334\n","step: 1400 \ttraining acc: 0.8195833333333333\n","step: 1450 \ttraining acc: 0.83\n","step: 1500 \ttraining acc: 0.7708333333333334\n","Test acc: 0.7627\n","step: 1550 \ttraining acc: 0.8604166666666667\n","step: 1600 \ttraining acc: 0.8204166666666667\n","step: 1650 \ttraining acc: 0.8491666666666666\n","step: 1700 \ttraining acc: 0.8316666666666667\n","step: 1750 \ttraining acc: 0.7720833333333333\n","step: 1800 \ttraining acc: 0.8316666666666667\n","step: 1850 \ttraining acc: 0.8154166666666667\n","step: 1900 \ttraining acc: 0.8041666666666667\n","step: 1950 \ttraining acc: 0.8045833333333333\n","step: 2000 \ttraining acc: 0.8066666666666666\n","Test acc: 0.7744\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","epochs = 2000\n","config = [\n","        ('conv2d', [64, 64, 3, 3, 1, 1]),\n","        ('bn', [64]),\n","        ('relu', [True]),\n","        ('max_pool2d', [2,2,0]),\n","        ('flatten', []),\n","        ('linear', [N, 64])\n","    ]\n","\n","# maml = Meta(config=config,fe=True,update_lr=meta_inner_lr,meta_lr=meta_outer_lr,n_way=N,\n","#             k_spt=support_size,k_qry=query_size,update_step=2,update_step_test=2,device=device).to(device)\n","\n","tmp = filter(lambda x: x.requires_grad, maml.parameters())\n","num = sum(map(lambda x: np.prod(x.shape), tmp))\n","print(maml)\n","print('Total trainable tensors:', num)\n","\n","\n","for step in range(1001,epochs+1):\n","\n","    x,y = iter(train_dataloader).next()\n","\n","    x_spt = np.empty(shape=(batch_size,N*support_size,1,28,28))\n","    x_qry = np.empty(shape=(batch_size,N*query_size,1,28,28))\n","    y_spt = np.empty(shape=(batch_size,N*support_size))\n","    y_qry = np.empty(shape=(batch_size,N*query_size))\n","    map_y_spt = np.empty(shape=(batch_size,N*support_size))\n","    map_y_qry = np.empty(shape=(batch_size,N*query_size))\n","\n","    num = (support_size+query_size)*N\n","\n","    for i in range(batch_size):\n","      x_spt[i]=x[i*(num):i*(num)+support_size*N]\n","      x_qry[i]=x[i*(num)+support_size*N:(i+1)*(num)]\n","      y_spt[i]=y[i*(num):i*(num)+support_size*N]\n","      y_qry[i]=y[i*(num)+support_size*N:(i+1)*(num)]\n","      map_y_spt[i] = map_labels(torch.from_numpy(y_spt[i]),N*support_size)\n","      map_y_qry[i] = map_labels(torch.from_numpy(y_qry[i]),N*query_size)\n","    x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device,dtype=torch.float), torch.from_numpy(y_spt).type(torch.LongTensor).to(device), \\\n","                                        torch.from_numpy(x_qry).to(device,dtype=torch.float), torch.from_numpy(y_qry).type(torch.LongTensor).to(device)\n","    \n","\n","\n","    map_y_spt = torch.from_numpy(map_y_spt).type(torch.LongTensor).to(device)\n","    map_y_qry = torch.from_numpy(map_y_qry).type(torch.LongTensor).to(device)\n","\n","    accs = maml(x_spt, map_y_spt, x_qry, map_y_qry)\n","    with open('/content/drive/MyDrive/MSC1400_1/AML/HW2/Practical/metatrain_2_acc.pickle', 'wb') as handle:\n","        pickle.dump(accs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    if step % 50 == 0:\n","            print('step:', step, '\\ttraining acc:', accs[-1])\n","\n","    if step % 500 == 0:\n","            accs = []\n","            for _ in range(1000//batch_size):\n","              # test\n","              x,y = iter(test_dataloader).next()\n","\n","              x_spt = np.empty(shape=(batch_size,N*support_size,1,28,28))\n","              x_qry = np.empty(shape=(batch_size,N*query_size,1,28,28))\n","              y_spt = np.empty(shape=(batch_size,N*support_size))\n","              y_qry = np.empty(shape=(batch_size,N*query_size))\n","              map_y_spt = np.empty(shape=(batch_size,N*support_size))\n","              map_y_qry = np.empty(shape=(batch_size,N*query_size))\n","              num = (support_size+query_size)*N\n","\n","              for i in range(batch_size):\n","                x_spt[i]=x[i*(num):i*(num)+support_size*N]\n","                x_qry[i]=x[i*(num)+support_size*N:(i+1)*(num)]\n","                y_spt[i]=y[i*(num):i*(num)+support_size*N]\n","                y_qry[i]=y[i*(num)+support_size*N:(i+1)*(num)]\n","                map_y_spt[i] = map_labels(y_spt[i],N*support_size)\n","                map_y_qry[i] = map_labels(y_qry[i],N*query_size)\n","              x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device,dtype=torch.float), torch.from_numpy(y_spt).type(torch.LongTensor).to(device), \\\n","                                        torch.from_numpy(x_qry).to(device,dtype=torch.float), torch.from_numpy(y_qry).type(torch.LongTensor).to(device)\n","    \n","              map_y_spt = torch.from_numpy(map_y_spt).type(torch.LongTensor).to(device)\n","              map_y_qry = torch.from_numpy(map_y_qry).type(torch.LongTensor).to(device)\n","              for x_spt_one, y_spt_one, x_qry_one, y_qry_one in zip(x_spt, map_y_spt, x_qry, map_y_qry):\n","                    test_acc = maml.finetunning(x_spt_one, y_spt_one, x_qry_one, y_qry_one)\n","                    accs.append( test_acc )\n","\n","            accs = np.array(accs).mean(axis=0).astype(np.float16)\n","            with open('/content/drive/MyDrive/MSC1400_1/AML/HW2/Practical/metatest_2_acc.pickle', 'wb') as handle:\n","                pickle.dump(accs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","            print('Test acc:', accs[-1])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ftPQO9FKWYJH"},"source":["# Update Step 3"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":751429,"status":"ok","timestamp":1649714354553,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"0bTvXzpZWbtj","outputId":"df8f4d6e-e089-475e-c48a-33ecbf77c1e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Meta(\n","  (net): Learner(\n","    (vars): ParameterList(\n","        (0): Parameter containing: [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)]\n","        (1): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (2): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (3): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (4): Parameter containing: [torch.cuda.FloatTensor of size 5x64 (GPU 0)]\n","        (5): Parameter containing: [torch.cuda.FloatTensor of size 5 (GPU 0)]\n","    )\n","    (vars_bn): ParameterList(\n","        (0): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (1): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","    )\n","  )\n",")\n","Total trainable tensors: 37381\n","step: 0 \ttraining acc: 0.5658333333333333\n","Test acc: 0.588\n","step: 50 \ttraining acc: 0.7804166666666666\n","step: 100 \ttraining acc: 0.8008333333333333\n","step: 150 \ttraining acc: 0.6608333333333334\n","step: 200 \ttraining acc: 0.7804166666666666\n","step: 250 \ttraining acc: 0.7616666666666667\n","step: 300 \ttraining acc: 0.86375\n","step: 350 \ttraining acc: 0.8066666666666666\n","step: 400 \ttraining acc: 0.8375\n","step: 450 \ttraining acc: 0.87375\n","step: 500 \ttraining acc: 0.895\n","Test acc: 0.827\n","step: 550 \ttraining acc: 0.8479166666666667\n","step: 600 \ttraining acc: 0.7754166666666666\n","step: 650 \ttraining acc: 0.86375\n","step: 700 \ttraining acc: 0.8933333333333333\n","step: 750 \ttraining acc: 0.87\n","step: 800 \ttraining acc: 0.8808333333333334\n","step: 850 \ttraining acc: 0.8558333333333333\n","step: 900 \ttraining acc: 0.89875\n","step: 950 \ttraining acc: 0.8775\n","step: 1000 \ttraining acc: 0.8545833333333334\n","Test acc: 0.834\n","step: 1050 \ttraining acc: 0.8341666666666666\n","step: 1100 \ttraining acc: 0.8875\n","step: 1150 \ttraining acc: 0.8470833333333333\n","step: 1200 \ttraining acc: 0.8629166666666667\n","step: 1250 \ttraining acc: 0.8625\n","step: 1300 \ttraining acc: 0.8633333333333333\n","step: 1350 \ttraining acc: 0.8633333333333333\n","step: 1400 \ttraining acc: 0.7975\n","step: 1450 \ttraining acc: 0.8970833333333333\n","step: 1500 \ttraining acc: 0.88875\n","Test acc: 0.8496\n","step: 1550 \ttraining acc: 0.8329166666666666\n","step: 1600 \ttraining acc: 0.88\n","step: 1650 \ttraining acc: 0.8629166666666667\n","step: 1700 \ttraining acc: 0.9029166666666667\n","step: 1750 \ttraining acc: 0.9216666666666666\n","step: 1800 \ttraining acc: 0.90875\n","step: 1850 \ttraining acc: 0.835\n","step: 1900 \ttraining acc: 0.8829166666666667\n","step: 1950 \ttraining acc: 0.86\n","step: 2000 \ttraining acc: 0.8666666666666667\n","Test acc: 0.8223\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","epochs = 2000\n","config = [\n","        ('conv2d', [64, 64, 3, 3, 1, 1]),\n","        ('bn', [64]),\n","        ('relu', [True]),\n","        ('max_pool2d', [2,2,0]),\n","        ('flatten', []),\n","        ('linear', [N, 64])\n","    ]\n","\n","maml = Meta(config=config,fe=True,update_lr=meta_inner_lr,meta_lr=meta_outer_lr,n_way=N,\n","            k_spt=support_size,k_qry=query_size,update_step=3,update_step_test=3,device=device).to(device)\n","\n","tmp = filter(lambda x: x.requires_grad, maml.parameters())\n","num = sum(map(lambda x: np.prod(x.shape), tmp))\n","print(maml)\n","print('Total trainable tensors:', num)\n","\n","\n","for step in range(epochs+1):\n","\n","    x,y = iter(train_dataloader).next()\n","\n","    x_spt = np.empty(shape=(batch_size,N*support_size,1,28,28))\n","    x_qry = np.empty(shape=(batch_size,N*query_size,1,28,28))\n","    y_spt = np.empty(shape=(batch_size,N*support_size))\n","    y_qry = np.empty(shape=(batch_size,N*query_size))\n","    map_y_spt = np.empty(shape=(batch_size,N*support_size))\n","    map_y_qry = np.empty(shape=(batch_size,N*query_size))\n","\n","    num = (support_size+query_size)*N\n","\n","    for i in range(batch_size):\n","      x_spt[i]=x[i*(num):i*(num)+support_size*N]\n","      x_qry[i]=x[i*(num)+support_size*N:(i+1)*(num)]\n","      y_spt[i]=y[i*(num):i*(num)+support_size*N]\n","      y_qry[i]=y[i*(num)+support_size*N:(i+1)*(num)]\n","      map_y_spt[i] = map_labels(torch.from_numpy(y_spt[i]),N*support_size)\n","      map_y_qry[i] = map_labels(torch.from_numpy(y_qry[i]),N*query_size)\n","    x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device,dtype=torch.float), torch.from_numpy(y_spt).type(torch.LongTensor).to(device), \\\n","                                        torch.from_numpy(x_qry).to(device,dtype=torch.float), torch.from_numpy(y_qry).type(torch.LongTensor).to(device)\n","    \n","\n","\n","    map_y_spt = torch.from_numpy(map_y_spt).type(torch.LongTensor).to(device)\n","    map_y_qry = torch.from_numpy(map_y_qry).type(torch.LongTensor).to(device)\n","\n","    accs = maml(x_spt, map_y_spt, x_qry, map_y_qry)\n","    with open('/content/drive/MyDrive/MSC1400_1/AML/HW2/Practical/metatrain_3_acc.pickle', 'wb') as handle:\n","        pickle.dump(accs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    if step % 50 == 0:\n","            print('step:', step, '\\ttraining acc:', accs[-1])\n","\n","    if step % 500 == 0:\n","            accs = []\n","            for _ in range(1000//batch_size):\n","              # test\n","              x,y = iter(test_dataloader).next()\n","\n","              x_spt = np.empty(shape=(batch_size,N*support_size,1,28,28))\n","              x_qry = np.empty(shape=(batch_size,N*query_size,1,28,28))\n","              y_spt = np.empty(shape=(batch_size,N*support_size))\n","              y_qry = np.empty(shape=(batch_size,N*query_size))\n","              map_y_spt = np.empty(shape=(batch_size,N*support_size))\n","              map_y_qry = np.empty(shape=(batch_size,N*query_size))\n","              num = (support_size+query_size)*N\n","\n","              for i in range(batch_size):\n","                x_spt[i]=x[i*(num):i*(num)+support_size*N]\n","                x_qry[i]=x[i*(num)+support_size*N:(i+1)*(num)]\n","                y_spt[i]=y[i*(num):i*(num)+support_size*N]\n","                y_qry[i]=y[i*(num)+support_size*N:(i+1)*(num)]\n","                map_y_spt[i] = map_labels(y_spt[i],N*support_size)\n","                map_y_qry[i] = map_labels(y_qry[i],N*query_size)\n","              x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device,dtype=torch.float), torch.from_numpy(y_spt).type(torch.LongTensor).to(device), \\\n","                                        torch.from_numpy(x_qry).to(device,dtype=torch.float), torch.from_numpy(y_qry).type(torch.LongTensor).to(device)\n","    \n","              map_y_spt = torch.from_numpy(map_y_spt).type(torch.LongTensor).to(device)\n","              map_y_qry = torch.from_numpy(map_y_qry).type(torch.LongTensor).to(device)\n","              for x_spt_one, y_spt_one, x_qry_one, y_qry_one in zip(x_spt, map_y_spt, x_qry, map_y_qry):\n","                    test_acc = maml.finetunning(x_spt_one, y_spt_one, x_qry_one, y_qry_one)\n","                    accs.append( test_acc )\n","\n","            accs = np.array(accs).mean(axis=0).astype(np.float16)\n","            with open('/content/drive/MyDrive/MSC1400_1/AML/HW2/Practical/metatest_3_acc.pickle', 'wb') as handle:\n","                pickle.dump(accs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","            print('Test acc:', accs[-1])\n"]},{"cell_type":"markdown","metadata":{"id":"E5X-lOSBN15I"},"source":["### Plot (2.5 points)"]},{"cell_type":"markdown","metadata":{"id":"5hDTwQqmNnX_"},"source":["Plot accuracy of meta-test phase based on inner loop update parameter."]},{"cell_type":"markdown","metadata":{"id":"go-Gjf6jqiar"},"source":["در این قسمت باتوجه به بهترین دقتی که در هر حالت در فاز متا تست داشتیم نمودار رسم شده که نشان می دهد با افزایش تعداد حلقه های درونی دقت افزایش می یابد."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":1367,"status":"ok","timestamp":1649714435115,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"Me9CYPgU0yf9","outputId":"048e55a9-c3b7-454e-e913-77c4f716ecf5"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["accuracies=[0.5396,0.7744,0.8496]\n","plt.plot(accuracies)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZTILlHKIIGfD"},"source":["## Without Feature Extractor"]},{"cell_type":"markdown","metadata":{"id":"NTDVBPWqOeNj"},"source":["### Train (10 points)"]},{"cell_type":"markdown","metadata":{"id":"LyYmPMOSN66S"},"source":["Now also add feature extractor network to your meta-network and repeat the same procedure like above cells just for inner loop update = 1.\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3570222,"status":"ok","timestamp":1649718520056,"user":{"displayName":"work space","userId":"16521137450774560864"},"user_tz":-270},"id":"4ALu1EEDQ0RQ","outputId":"6963cabe-ed30-4f9a-ece2-25ea6faf8f98"},"outputs":[{"name":"stdout","output_type":"stream","text":["Meta(\n","  (net): Learner(\n","    (vars): ParameterList(\n","        (0): Parameter containing: [torch.cuda.FloatTensor of size 64x1x3x3 (GPU 0)]\n","        (1): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (2): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (3): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (4): Parameter containing: [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)]\n","        (5): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (6): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (7): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (8): Parameter containing: [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)]\n","        (9): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (10): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (11): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (12): Parameter containing: [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)]\n","        (13): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (14): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (15): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (16): Parameter containing: [torch.cuda.FloatTensor of size 5x64 (GPU 0)]\n","        (17): Parameter containing: [torch.cuda.FloatTensor of size 5 (GPU 0)]\n","    )\n","    (vars_bn): ParameterList(\n","        (0): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (1): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (2): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (3): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (4): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (5): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (6): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","        (7): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n","    )\n","  )\n",")\n","Total trainable tensors: 112261\n","step: 0 \ttraining acc: 0.27875\n","Test acc: 0.2534\n","step: 50 \ttraining acc: 0.28125\n","step: 100 \ttraining acc: 0.3\n","step: 150 \ttraining acc: 0.2816666666666667\n","step: 200 \ttraining acc: 0.27875\n","step: 250 \ttraining acc: 0.27458333333333335\n","step: 300 \ttraining acc: 0.2775\n","step: 350 \ttraining acc: 0.26\n","step: 400 \ttraining acc: 0.2504166666666667\n","step: 450 \ttraining acc: 0.2675\n","step: 500 \ttraining acc: 0.2679166666666667\n","Test acc: 0.2588\n","step: 550 \ttraining acc: 0.2679166666666667\n","step: 600 \ttraining acc: 0.2725\n","step: 650 \ttraining acc: 0.2891666666666667\n","step: 700 \ttraining acc: 0.2683333333333333\n","step: 750 \ttraining acc: 0.27125\n","step: 800 \ttraining acc: 0.24833333333333332\n","step: 850 \ttraining acc: 0.32416666666666666\n","step: 900 \ttraining acc: 0.2808333333333333\n","step: 950 \ttraining acc: 0.2920833333333333\n","step: 1000 \ttraining acc: 0.27958333333333335\n","Test acc: 0.2551\n","step: 1050 \ttraining acc: 0.28708333333333336\n","step: 1100 \ttraining acc: 0.24125\n","step: 1150 \ttraining acc: 0.2625\n","step: 1200 \ttraining acc: 0.28375\n","step: 1250 \ttraining acc: 0.30625\n","step: 1300 \ttraining acc: 0.2625\n","step: 1350 \ttraining acc: 0.26875\n","step: 1400 \ttraining acc: 0.325\n","step: 1450 \ttraining acc: 0.2525\n","step: 1500 \ttraining acc: 0.25083333333333335\n","Test acc: 0.253\n","step: 1550 \ttraining acc: 0.2808333333333333\n","step: 1600 \ttraining acc: 0.26416666666666666\n","step: 1650 \ttraining acc: 0.27375\n","step: 1700 \ttraining acc: 0.28125\n","step: 1750 \ttraining acc: 0.27875\n","step: 1800 \ttraining acc: 0.28958333333333336\n","step: 1850 \ttraining acc: 0.25166666666666665\n","step: 1900 \ttraining acc: 0.29625\n","step: 1950 \ttraining acc: 0.275\n","step: 2000 \ttraining acc: 0.285\n","Test acc: 0.2588\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#################################################################################\n","#                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n","#################################################################################\n","# Define your config and initialize model and parameters\n","# prepare your data as input to your model.\n","# train meta-network\n","# get acurracy of model in meta-test phase\n","#################################################################################\n","\n","inner_loop_update = 1\n","\n","\n","config = [\n","        ('conv2d', [64, 1, 3, 3, 1, 1]),\n","        ('bn', [64]),\n","        ('relu', [True]),\n","        ('max_pool2d', [2,2,0]),\n","        ('conv2d', [64, 64, 3, 3, 1, 1]),\n","        ('bn', [64]),\n","        ('relu', [True]),\n","        ('max_pool2d', [2,2,0]),\n","        ('conv2d', [64, 64, 3, 3, 1, 1]),\n","        ('bn', [64]),\n","        ('relu', [True]),\n","        ('max_pool2d', [2,2,0]),\n","        ('conv2d', [64, 64, 3, 3, 1, 1]),\n","        ('bn', [64]),\n","        ('relu', [True]),\n","        ('max_pool2d', [2,2,0]),\n","        ('flatten', []),\n","        ('linear', [N, 64])\n","    ]\n","\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","epochs = 2000\n","\n","\n","maml = Meta(config=config,fe=False,update_lr=meta_inner_lr,meta_lr=meta_outer_lr,n_way=N,\n","            k_spt=support_size,k_qry=query_size,update_step=inner_loop_update,update_step_test=inner_loop_update,device=device).to(device)\n","\n","tmp = filter(lambda x: x.requires_grad, maml.parameters())\n","num = sum(map(lambda x: np.prod(x.shape), tmp))\n","print(maml)\n","print('Total trainable tensors:', num)\n","\n","\n","for step in range(epochs+1):\n","\n","    x,y = iter(train_dataloader).next()\n","\n","    x_spt = np.empty(shape=(batch_size,N*support_size,1,28,28))\n","    x_qry = np.empty(shape=(batch_size,N*query_size,1,28,28))\n","    y_spt = np.empty(shape=(batch_size,N*support_size))\n","    y_qry = np.empty(shape=(batch_size,N*query_size))\n","    map_y_spt = np.empty(shape=(batch_size,N*support_size))\n","    map_y_qry = np.empty(shape=(batch_size,N*query_size))\n","\n","    num = (support_size+query_size)*N\n","\n","    for i in range(batch_size):\n","      x_spt[i]=x[i*(num):i*(num)+support_size*N]\n","      x_qry[i]=x[i*(num)+support_size*N:(i+1)*(num)]\n","      y_spt[i]=y[i*(num):i*(num)+support_size*N]\n","      y_qry[i]=y[i*(num)+support_size*N:(i+1)*(num)]\n","      map_y_spt[i] = map_labels(torch.from_numpy(y_spt[i]),N*support_size)\n","      map_y_qry[i] = map_labels(torch.from_numpy(y_qry[i]),N*query_size)\n","    x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device,dtype=torch.float), torch.from_numpy(y_spt).type(torch.LongTensor).to(device), \\\n","                                        torch.from_numpy(x_qry).to(device,dtype=torch.float), torch.from_numpy(y_qry).type(torch.LongTensor).to(device)\n","    \n","\n","\n","    map_y_spt = torch.from_numpy(map_y_spt).type(torch.LongTensor).to(device)\n","    map_y_qry = torch.from_numpy(map_y_qry).type(torch.LongTensor).to(device)\n","\n","    accs = maml(x_spt, map_y_spt, x_qry, map_y_qry)\n","    with open('/content/drive/MyDrive/MSC1400_1/AML/HW2/Practical/metatrain_4_acc.pickle', 'wb') as handle:\n","        pickle.dump(accs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    if step % 50 == 0:\n","            print('step:', step, '\\ttraining acc:', accs[-1])\n","\n","    if step % 500 == 0:\n","            accs = []\n","            for _ in range(1000//batch_size):\n","              # test\n","              x,y = iter(test_dataloader).next()\n","\n","              x_spt = np.empty(shape=(batch_size,N*support_size,1,28,28))\n","              x_qry = np.empty(shape=(batch_size,N*query_size,1,28,28))\n","              y_spt = np.empty(shape=(batch_size,N*support_size))\n","              y_qry = np.empty(shape=(batch_size,N*query_size))\n","              map_y_spt = np.empty(shape=(batch_size,N*support_size))\n","              map_y_qry = np.empty(shape=(batch_size,N*query_size))\n","              num = (support_size+query_size)*N\n","\n","              for i in range(batch_size):\n","                x_spt[i]=x[i*(num):i*(num)+support_size*N]\n","                x_qry[i]=x[i*(num)+support_size*N:(i+1)*(num)]\n","                y_spt[i]=y[i*(num):i*(num)+support_size*N]\n","                y_qry[i]=y[i*(num)+support_size*N:(i+1)*(num)]\n","                map_y_spt[i] = map_labels(y_spt[i],N*support_size)\n","                map_y_qry[i] = map_labels(y_qry[i],N*query_size)\n","              x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device,dtype=torch.float), torch.from_numpy(y_spt).type(torch.LongTensor).to(device), \\\n","                                        torch.from_numpy(x_qry).to(device,dtype=torch.float), torch.from_numpy(y_qry).type(torch.LongTensor).to(device)\n","    \n","              map_y_spt = torch.from_numpy(map_y_spt).type(torch.LongTensor).to(device)\n","              map_y_qry = torch.from_numpy(map_y_qry).type(torch.LongTensor).to(device)\n","              for x_spt_one, y_spt_one, x_qry_one, y_qry_one in zip(x_spt, map_y_spt, x_qry, map_y_qry):\n","                    test_acc = maml.finetunning(x_spt_one, y_spt_one, x_qry_one, y_qry_one)\n","                    accs.append( test_acc )\n","\n","            accs = np.array(accs).mean(axis=0).astype(np.float16)\n","            with open('/content/drive/MyDrive/MSC1400_1/AML/HW2/Practical/metatest_4_acc.pickle', 'wb') as handle:\n","                pickle.dump(accs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","            print('Test acc:', accs[-1])\n","\n","#################################################################################\n","#                                   THE END                                     #\n","#################################################################################\n"]},{"cell_type":"markdown","metadata":{"id":"6qSBg8MQO9aF"},"source":["### Report (2.5 points)"]},{"cell_type":"markdown","metadata":{"id":"ylzdpCPfOZSJ"},"source":["Report accuracy of meta-test phase."]},{"cell_type":"markdown","metadata":{"id":"bbkNdFESrR-i"},"source":["با توجه به نتایچ بالا می بینیم که در بهترین حالت دقت فاز متاتست 0.2588 شده است."]},{"cell_type":"markdown","metadata":{"id":"QVX1qagbRGvV"},"source":["## Compare and explain Results"]},{"cell_type":"markdown","metadata":{"id":"UOKygCh_Rhkc"},"source":["Answer:\n","\n","<br>\n","\n","همان طور که در این دو قسمت مشاهده کردیم زمانی که از مدل پری ترین شده برای استخراج ویژگی استفاده شد و متاپارامترها فقط لایه آخر بودند نتایج نسبت به حالت آخر که کل شبکه متا پارامترها بودند بهتر بود. با توجه به این که تعداد پارامترهایی که باید ترین می شدند افزایش یافته بود و با تعداد ایپاک یکسان نتایج مقایسه می شوند طبیعی است که مدلی که از خروجی مدل پری ترین شده استفاده می کرد نتایج بهتری داشته باشد. به علاوه عملکرد مدل در حالت اول نیز با افزایش تعداد حلقه های درونی بهبود می یافت چرا که پارامترهای خاص تسک با افزایش تعداد تکرار حلقه داخلی بهتر میشوند به همین دلیل می توان گفت باعث بهبود یادکیری متاپارامترها نیز می شوند تا در مواجهه با تسک های جدید قابلیت یادگیری بیشتری داشته باشند.\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"MAML.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
