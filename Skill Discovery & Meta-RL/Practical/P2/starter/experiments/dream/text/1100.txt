Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10691852867603302
Distance: 8.720688819885254
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.24815481901168823
Distance: 8.627607345581055
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.10893268883228302
Distance: 8.675762176513672
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 1, 0, 0])
Action: noop
Reward: -0.16673488914966583
Distance: 8.584694862365723
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.15193481743335724
Distance: 8.551429748535156
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.13188476860523224
Distance: 8.503364562988281
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.21202106773853302
Distance: 8.435249328613281
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.254952609539032
Distance: 8.447270393371582
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.17601986229419708
Distance: 8.502223014831543
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.20410747826099396
Distance: 8.478242874145508
Next state: tensor([2, 1, 1, 0])
================================================================================

