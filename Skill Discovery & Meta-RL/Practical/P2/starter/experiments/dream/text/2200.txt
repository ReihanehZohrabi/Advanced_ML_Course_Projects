Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.31816691160202026
Distance: 7.694853782653809
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1516992598772049
Distance: 7.813020706176758
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 0.03850727528333664
Distance: 7.7647199630737305
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 6])
Action: pickup
Reward: -0.20866413414478302
Distance: 7.526212692260742
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 6])
Action: right
Reward: -0.022345736622810364
Distance: 7.534876823425293
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 6])
Action: noop
Reward: -0.12351150810718536
Distance: 7.357222557067871
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 6])
Action: pickup
Reward: -0.2453734278678894
Distance: 7.280734062194824
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 6])
Action: end_episode
Reward: -0.14613981544971466
Distance: 7.326107501983643
Next state: tensor([4, 2, 0, 6])
================================================================================

