Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.35426539182662964
Distance: 8.67427921295166
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.2866317629814148
Distance: 8.828544616699219
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 3.4148387908935547
Distance: 8.915176391601562
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 7])
Action: right
Reward: 1.319153070449829
Distance: 5.300337791442871
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 7])
Action: left
Reward: 0.39981919527053833
Distance: 3.781184673309326
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09967584908008575
Distance: 3.181365489959717
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.2869393229484558
Distance: 3.0810413360595703
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.27588433027267456
Distance: 3.167980670928955
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.29997938871383667
Distance: 3.2438650131225586
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 2, 1, 0])
Action: right
Reward: 0.30483776330947876
Distance: 3.343844413757324
Next state: tensor([4, 2, 0, 7])
================================================================================

