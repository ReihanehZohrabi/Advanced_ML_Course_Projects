Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: 1.3524997234344482
Distance: 26.078285217285156
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.12112922966480255
Distance: 24.525785446166992
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: left
Reward: -0.3247520327568054
Distance: 24.446914672851562
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 0, 0])
Action: left
Reward: -0.23725241422653198
Distance: 24.571666717529297
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 1, 0, 0])
Action: right
Reward: -0.198130801320076
Distance: 24.608919143676758
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 0, 0])
Action: down
Reward: -0.12435264885425568
Distance: 24.6070499420166
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 0, 0, 0])
Action: drop
Reward: -0.24047774076461792
Distance: 24.531402587890625
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 0, 0, 0])
Action: noop
Reward: -0.2453128695487976
Distance: 24.571880340576172
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 0, 0, 0])
Action: drop
Reward: -0.18367882072925568
Distance: 24.6171932220459
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0, 0])
Action: pickup
Reward: -0.1351158171892166
Distance: 24.600872039794922
Next state: tensor([1, 0, 0, 0])
================================================================================

