Env ID: [20]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1596204787492752
Distance: 9.457042694091797
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.06261749565601349
Distance: 9.41666316986084
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.18688221275806427
Distance: 9.279280662536621
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.292614459991455
Distance: 9.266162872314453
Next state: tensor([ 4,  2,  0, 21])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 4,  2,  0, 21])
Action: left
Reward: 0.9832191467285156
Distance: 1.7735486030578613
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.03060154616832733
Distance: 0.5903294086456299
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.15016789734363556
Distance: 0.420930951833725
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.17631374299526215
Distance: 0.3710988461971283
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.18177999556064606
Distance: 0.3474125862121582
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.22281648218631744
Distance: 0.329192578792572
Next state: tensor([2, 2, 0, 0])
================================================================================

