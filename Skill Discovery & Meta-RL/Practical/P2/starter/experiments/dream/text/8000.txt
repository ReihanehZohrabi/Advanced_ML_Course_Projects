Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.226362407207489
Distance: 8.267314910888672
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.851092338562012
Distance: 8.29367733001709
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 13])
Action: ride_bus
Reward: -0.0020330697298049927
Distance: 0.24258530139923096
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 4,  2,  0, 13])
Action: left
Reward: -0.1927400827407837
Distance: 0.044618360698223114
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.1759536862373352
Distance: 0.03735845163464546
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.19637705385684967
Distance: 0.013312146067619324
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.20063330233097076
Distance: 0.009689195081591606
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.20109589397907257
Distance: 0.010322497226297855
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.2779901921749115
Distance: 0.011418385431170464
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 13])
Action: left
Reward: -0.16368943452835083
Distance: 0.08940859138965607
Next state: tensor([3, 2, 1, 0])
================================================================================

