Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.21185798943042755
Distance: 7.654098033905029
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.329665184020996
Distance: 7.665956020355225
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 6])
Action: left
Reward: -0.07688269764184952
Distance: 0.1362909972667694
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.20311732590198517
Distance: 0.013173689134418964
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.21337877213954926
Distance: 0.01629101298749447
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: up
Reward: -0.21075329184532166
Distance: 0.029669780284166336
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.1864088475704193
Distance: 0.040423065423965454
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.2160312533378601
Distance: 0.026831921190023422
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: right
Reward: -0.21263933181762695
Distance: 0.042863164097070694
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.22382156550884247
Distance: 0.055502504110336304
Next state: tensor([2, 2, 0, 0])
================================================================================

