Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.23097914457321167
Distance: 8.316849708557129
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.970943927764893
Distance: 8.34782886505127
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 13])
Action: left
Reward: -0.03956852853298187
Distance: 0.17688444256782532
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.20853763818740845
Distance: 0.016452964395284653
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.191994771361351
Distance: 0.024990588426589966
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: up
Reward: -0.20237281918525696
Distance: 0.01698535680770874
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.1935875564813614
Distance: 0.019358161836862564
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.2042655348777771
Distance: 0.012945713475346565
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.20696896314620972
Distance: 0.017211249098181725
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.20841357111930847
Distance: 0.024180211126804352
Next state: tensor([1, 3, 0, 0])
================================================================================

