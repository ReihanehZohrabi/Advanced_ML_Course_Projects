Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.2138187438249588
Distance: 8.385391235351562
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.058198928833008
Distance: 8.399209976196289
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 13])
Action: up
Reward: -0.08332102000713348
Distance: 0.1410103440284729
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.1936652511358261
Distance: 0.024331361055374146
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.1933954656124115
Distance: 0.01799660734832287
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.1973731815814972
Distance: 0.01139206625521183
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 4, 0, 0])
Action: up
Reward: -0.19990259408950806
Distance: 0.008765235543251038
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0, 0])
Action: ride_bus
Reward: -0.2000424563884735
Distance: 0.008667830377817154
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0, 0])
Action: ride_bus
Reward: -0.20314419269561768
Distance: 0.008710278198122978
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 4, 0, 0])
Action: end_episode
Reward: -0.2154194563627243
Distance: 0.011854478158056736
Next state: tensor([2, 4, 0, 0])
================================================================================

