Env ID: [13]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.204844668507576
Distance: 8.682523727416992
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.427725791931152
Distance: 8.687368392944336
Next state: tensor([ 4,  2,  0, 14])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 14])
Action: left
Reward: -0.16530108451843262
Distance: 0.05964222177863121
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.18456117808818817
Distance: 0.024943292140960693
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.20347699522972107
Distance: 0.009504465386271477
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.20114535093307495
Distance: 0.012981466948986053
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: up
Reward: -0.2062629759311676
Distance: 0.014126813039183617
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.1920684278011322
Distance: 0.02038978785276413
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.20281583070755005
Distance: 0.012458216398954391
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.20571592450141907
Distance: 0.015274053439497948
Next state: tensor([1, 3, 0, 0])
================================================================================

